import logging
import json
import asyncio
import aiohttp
from openai import AsyncOpenAI
from config import BOT_CONFIG
from services.memory import get_history, get_user_summary

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter
client = None

CATEGORY_TITLES = {
    "free": "–ë–ï–°–ü–õ–ê–¢–ù–´–ï –ú–û–î–ï–õ–ò:",
    "large_context": "–ú–û–î–ï–õ–ò –° –ë–û–õ–¨–®–ò–ú –ö–û–ù–¢–ï–ö–°–¢–û–ú (‚â•100K):",
    "specialized": "–°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ú–û–î–ï–õ–ò:",
    "paid": "–ü–õ–ê–¢–ù–´–ï –ú–û–î–ï–õ–ò:",
}

def init_client():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenRouter –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    global client
    if client is None:
        logger.info("Initializing OpenRouter client")
        client = AsyncOpenAI(
            api_key=BOT_CONFIG["OPENROUTER_API_KEY"],
            base_url=BOT_CONFIG["OPENROUTER_BASE_URL"],
            default_headers={
                "HTTP-Referer": BOT_CONFIG["BOT_REFERER"],
                "X-Title": BOT_CONFIG["BOT_TITLE"]
            }
        )
        logger.info("OpenRouter client initialized successfully")
    return client

async def check_model_availability(model: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤ OpenRouter API."""
    try:
        client = init_client()
        logger.info(f"Checking availability of model: {model}")
        response = await client.models.list()
        
        if not response or not hasattr(response, 'data'):
            logger.error("Failed to get models list from OpenRouter API")
            return False
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Å–ø–∏—Å–∫–µ
        for available_model in response.data:
            model_data = available_model if isinstance(available_model, dict) else available_model.model_dump()
            if model_data.get('id') == model:
                logger.info(f"Model {model} is available")
                return True
                
        logger.error(f"Model {model} is not available in OpenRouter API")
        return False
    except Exception as e:
        logger.error(f"Error checking model availability: {str(e)}")
        return False


async def fetch_models_data() -> list[dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ OpenRouter."""
    try:
        client = init_client()
        response = await client.models.list()

        if not response:
            logger.error("Empty response while fetching models data")
            return []

        raw_models = []
        if hasattr(response, "data"):
            raw_models = response.data
        elif isinstance(response, list):
            raw_models = response
        else:
            logger.error(f"Unexpected models response format: {response}")
            return []

        normalized_models: list[dict] = []
        for model in raw_models:
            if isinstance(model, dict):
                normalized_models.append(model)
            elif hasattr(model, "model_dump"):
                normalized_models.append(model.model_dump())
            else:
                logger.warning(f"Skipping model with unknown type: {model}")

        return normalized_models
    except Exception as e:
        logger.error(f"Error fetching models data: {str(e)}")
        return []


def _is_free_pricing(prompt_price) -> bool:
    try:
        return float(prompt_price) == 0
    except (TypeError, ValueError):
        return False


def categorize_models(models_data: list[dict]) -> dict[str, list[dict]]:
    """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
    categories: dict[str, list[dict]] = {
        "free": [],
        "large_context": [],
        "specialized": [],
        "paid": [],
    }

    for model in models_data:
        model_id = model.get("id", "Unknown")
        context_length = model.get("context_length", 0) or 0
        pricing = model.get("pricing", {}) if isinstance(model.get("pricing"), dict) else {}
        prompt_price = pricing.get("prompt")

        is_free = ":free" in model_id or _is_free_pricing(prompt_price)
        is_large_context = context_length >= 100_000
        is_specialized = any(
            keyword in model_id.lower()
            for keyword in ["instruct", "coding", "research", "solidity", "math"]
        )

        if is_free:
            categories["free"].append(model)
        elif is_large_context:
            categories["large_context"].append(model)
        elif is_specialized:
            categories["specialized"].append(model)
        else:
            categories["paid"].append(model)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –¥–ª–∏–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—É–±—ã–≤–∞–Ω–∏—é)
    for key, models in categories.items():
        categories[key] = sorted(models, key=lambda m: m.get("context_length", 0) or 0, reverse=True)

    return categories


def format_model_list(
    categories: dict[str, list[dict]],
    order: list[str],
    category_titles: dict[str, str],
    header: str | None = "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n\n",
    max_items_per_category: int | None = 20,
) -> list[str]:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –µ–≥–æ –Ω–∞ —á–∞—Å—Ç–∏."""

    max_length = 3000
    message_parts: list[str] = []
    current_part = header or ""

    for key in order:
        models = categories.get(key, [])
        if not models:
            continue

        category_block = f"{category_titles.get(key, key)}\n"
        displayed_models = models if max_items_per_category is None else models[:max_items_per_category]

        for model in displayed_models:
            context_length = model.get("context_length", 0)
            context_kb = context_length / 1024 if context_length else 0
            context_str = f"{context_kb:.0f}K" if context_kb > 0 else "N/A"
            category_block += f"‚Ä¢ {model.get('id', 'Unknown')} ({context_str})\n"

        if max_items_per_category is not None:
            remaining = len(models) - len(displayed_models)
            if remaining > 0:
                category_block += f"‚Ä¶–∏ –µ—â–µ {remaining} –º–æ–¥–µ–ª–µ–π –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n"

        category_block += "\n"

        if len(current_part) + len(category_block) > max_length:
            if current_part:
                message_parts.append(current_part)
            current_part = category_block
        else:
            current_part += category_block

    if current_part:
        message_parts.append(current_part)

    return message_parts


async def build_models_messages(
    order: list[str],
    header: str | None = "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n\n",
    max_items_per_category: int | None = 20,
) -> list[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –≤—ã–¥–∞—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."""

    models_data = await fetch_models_data()
    if not models_data:
        return []

    categories = categorize_models(models_data)
    return format_model_list(
        categories,
        order,
        CATEGORY_TITLES,
        header=header,
        max_items_per_category=max_items_per_category,
    )


async def choose_best_free_model() -> str | None:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∞–º—É—é –º–æ—â–Ω—É—é –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    models_data = await fetch_models_data()
    if not models_data:
        return None

    free_models = [
        model
        for model in models_data
        if ":free" in model.get("id", "") or _is_free_pricing(model.get("pricing", {}).get("prompt"))
    ]

    if not free_models:
        logger.warning("No free models available in OpenRouter response")
        return None

    best_model = max(free_models, key=lambda m: m.get("context_length", 0) or 0)
    best_model_id = best_model.get("id")
    logger.info(f"Selected best free model: {best_model_id}")
    return best_model_id

async def generate_text(prompt: str, model: str, chat_id: str = None, user_id: str = None) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenRouter API."""
    client = init_client()
    
    messages = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    if BOT_CONFIG["CUSTOM_SYSTEM_PROMPT"]:
        messages.append({"role": "system", "content": BOT_CONFIG["CUSTOM_SYSTEM_PROMPT"]})
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã chat_id –∏ user_id, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    if chat_id and user_id:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        history = get_history(chat_id, user_id, limit=10)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        summary = get_user_summary(chat_id, user_id)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –µ–µ –∫–∞–∫ —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if summary:
            messages.append({"role": "system", "content": f"–ö—Ä–∞—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –Ω–∞—à–µ–≥–æ –æ–±—â–µ–Ω–∏—è: {summary}"})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        for msg in reversed(history):
            if msg["role"] in ["user", "assistant"]:
                messages.append({"role": msg["role"], "content": msg["text"]})
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –æ–Ω –µ—â–µ –Ω–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏
    current_prompt_in_history = False
    if chat_id and user_id:
        if history and history[0].get("role") == "user" and history[0].get("text") == prompt:
            current_prompt_in_history = True

    if not current_prompt_in_history:
        messages.append({"role": "user", "content": prompt})

    try:
        logger.info(f"Sending text generation request to OpenRouter with model: {model}, prompt: {prompt}")
        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=BOT_CONFIG["TEXT_GENERATION"]["MAX_TOKENS"],
            temperature=BOT_CONFIG["TEXT_GENERATION"]["TEMPERATURE"]
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
        if not response or not hasattr(response, 'choices') or not response.choices:
            logger.error("Empty or invalid response from OpenRouter API")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        try:
            result = response.choices[0].message.content.strip()
            if not result:
                logger.error("Empty content in response from OpenRouter API")
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            logger.info(f"Received response from OpenRouter: {result[:100]}...")
            return result
        except (AttributeError, IndexError) as e:
            logger.error(f"Error extracting content from response: {str(e)}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            
    except Exception as e:
        logger.error(f"Error generating text: {str(e)}")
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}"

async def generate_image(prompt: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é PiAPI.ai."""
    if not BOT_CONFIG["PIAPI_KEY"]:
        logger.error("PIAPI_KEY environment variable is not set.")
        return "–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –ö–ª—é—á API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω."

    try:
        url = "https://api.piapi.ai/api/v1/task"
        headers = {
            "X-API-Key": BOT_CONFIG["PIAPI_KEY"],
            "Content-Type": "application/json"
        }

        payload = {
            "model": BOT_CONFIG["IMAGE_GENERATION"]["MODEL"],
            "task_type": BOT_CONFIG["IMAGE_GENERATION"]["TASK_TYPE"],
            "input": {
                "prompt": prompt,
                "negative_prompt": BOT_CONFIG["IMAGE_GENERATION"]["NEGATIVE_PROMPT"],
                "aspect_ratio": BOT_CONFIG["IMAGE_GENERATION"]["ASPECT_RATIO"]
            }
        }

        async with aiohttp.ClientSession() as session:
            # 1. –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            logger.info(f"Sending image generation request to PiAPI.ai for prompt: {prompt}")
            async with session.post(url, headers=headers, data=json.dumps(payload)) as response:
                if response.status != 200:
                    error_text = await response.text()
                    logger.error(f"PiAPI.ai Error Response: {error_text} (Status: {response.status})")
                    raise Exception(f"Failed to start PiAPI.ai image generation: {error_text}")

                task_data = await response.json()
                data_dict = task_data.get("data")
                task_id = data_dict.get("task_id") if data_dict else None

                if not task_id:
                    logger.error(f"No task_id received from PiAPI.ai: {task_data}")
                    raise Exception("No task_id received from PiAPI.ai")

                logger.info(f"Started PiAPI.ai image generation task: {task_id}")

            # 2. –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏
            max_attempts = BOT_CONFIG["IMAGE_GENERATION"]["MAX_ATTEMPTS"]
            attempts = 0
            status_check_url = f"{url}/{task_id}"

            while attempts < max_attempts:
                await asyncio.sleep(BOT_CONFIG["IMAGE_GENERATION"]["POLLING_INTERVAL"])
                logger.info(f"Checking status for task {task_id} (Attempt {attempts + 1}/{max_attempts})")
                async with session.get(status_check_url, headers=headers) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"Status check failed for task {task_id}: {error_text} (Status: {response.status})")
                        attempts += 1
                        continue

                    status_data = await response.json()
                    data_dict = status_data.get("data", {})
                    task_status = data_dict.get("status")
                    logger.info(f"Task {task_id} status: {task_status}")

                    if task_status == "completed":
                        output_dict = data_dict.get("output", {})
                        image_url = output_dict.get("image_url")
                        if image_url:
                            logger.info(f"Image generation successful for task {task_id}: {image_url}")
                            return image_url
                        else:
                            logger.error(f"Completed task {task_id} but no result URL found: {status_data}")
                            raise Exception("No image URL in successful PiAPI.ai response")
                    elif task_status == "failed":
                        error_details = data_dict.get("error", {}).get("message", "Unknown error")
                        logger.error(f"Image generation failed for task {task_id}: {error_details}")
                        raise Exception(f"PiAPI.ai image generation failed: {error_details}")
                    elif task_status in ["processing", "pending"]:
                        pass
                    else:
                        logger.warning(f"Unknown task status for {task_id}: {task_status}")

                    attempts += 1

            logger.error(f"Image generation timed out for task {task_id}")
            raise Exception("Image generation timed out with PiAPI.ai")

    except Exception as e:
        logger.error(f"Error generating image with PiAPI.ai: {str(e)}", exc_info=True)
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ PiAPI.ai: {str(e)}" 