import logging
from telegram import Update
from telegram.ext import ContextTypes
from utils.helpers import escape_markdown_v2
from config import BOT_CONFIG
from services.memory import start_new_dialog, clear_memory
from services.generation import init_client, fetch_models_data, categorize_models

logger = logging.getLogger(__name__)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start."""
    user = update.effective_user
    user_mention = user.mention_markdown_v2()
    default_model_escaped = escape_markdown_v2(BOT_CONFIG["DEFAULT_MODEL"])

    text = (
        f"–ü—Ä–∏–≤–µ—Ç, {user_mention}\\! –Ø –±–æ—Ç\\-–ø–æ–º–æ—â–Ω–∏–∫\\.\n\n"
        f"üìù –°–ø—Ä–æ—Å–∏ –º–µ–Ω—è —á—Ç–æ\\-–Ω–∏–±—É–¥—å, –∏ —è –æ—Ç–≤–µ—á—É —Å –ø–æ–º–æ—â—å—é `{default_model_escaped}`\\.\n"
        f"üé® –ü–æ–ø—Ä–æ—Å–∏ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É \\(–Ω–∞–ø—Ä–∏–º–µ—Ä, '–Ω–∞—Ä–∏—Å—É–π –∑–∞–∫–∞—Ç –Ω–∞–¥ –º–æ—Ä–µ–º'\\)\\.\n"
        f"ü§ñ –•–æ—á–µ—à—å –æ—Ç–≤–µ—Ç –æ—Ç –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏? –£–∫–∞–∂–∏ –µ–µ –≤ –∫–æ–Ω—Ü–µ –∑–∞–ø—Ä–æ—Å–∞ \\(–Ω–∞–ø—Ä–∏–º–µ—Ä, '\\.\\.\\. —á–µ—Ä–µ–∑ deepseek', '\\.\\.\\. via claude'\\) –∏–ª–∏ –≤ –Ω–∞—á–∞–ª–µ \\(–Ω–∞–ø—Ä–∏–º–µ—Ä, 'chatgpt –∫–∞–∫–æ–π —Å–µ–≥–æ–¥–Ω—è –¥–µ–Ω—å?'\\)\\.\n"
        f"   –°–µ–π—á–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: deepseek, chatgpt, claude\\.\n\n"
        f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–π /new –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ \\(—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é\\)\\.\n"
        f"üßπ –ò—Å–ø–æ–ª—å–∑—É–π /clear –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏\\.\n"
        f"‚ùì –ò—Å–ø–æ–ª—å–∑—É–π /help –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏\\."
    )

    await update.message.reply_markdown_v2(text=text)

async def new_dialog(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /new - –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞."""
    user = update.effective_user
    chat_id = str(update.effective_chat.id)
    user_id = str(user.id)
    
    # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –±—É–¥—É—â–µ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
    session_id = start_new_dialog(chat_id, user_id)
    
    user_mention = user.mention_markdown_v2()
    await update.message.reply_markdown_v2(
        f"–ü—Ä–∏–≤–µ—Ç, {user_mention}\\! –ù–∞—á–∏–Ω–∞—é –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥\\.\n"
        f"–ò—Å—Ç–æ—Ä–∏—è –Ω–∞—à–µ–≥–æ –æ–±—â–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –≤ –±—É–¥—É—â–µ–º\\."
    )

async def clear_memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /clear - –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏."""
    user = update.effective_user
    chat_id = str(update.effective_chat.id)
    user_id = str(user.id)
    
    # –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
    clear_memory(chat_id, user_id)
    
    user_mention = user.mention_markdown_v2()
    await update.message.reply_markdown_v2(
        f"{user_mention}, –ø–∞–º—è—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞\\.\n"
        f"–ù–∞—á–∏–Ω–∞—é –¥–∏–∞–ª–æ–≥ —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞\\."
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help - —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º."""
    user = update.effective_user
    user_mention = user.mention_markdown_v2()
    
    text = (
        f"–ü—Ä–∏–≤–µ—Ç, {user_mention}\\! –í–æ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥:\n\n"
        f"üìù /new \\- –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ \\(—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\\)\n"
        f"üßπ /clear \\- –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –±–æ—Ç–∞\n"
        f"‚ùì /help \\- –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É\n"
        f"ü§ñ /models \\- –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n\n"
        f"–¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ:\n"
        f"‚Ä¢ –ó–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –±–æ—Ç—É\n"
        f"‚Ä¢ –ü—Ä–æ—Å–∏—Ç—å –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏\n"
        f"‚Ä¢ –£–∫–∞–∑—ã–≤–∞—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ \\(–Ω–∞–ø—Ä–∏–º–µ—Ä, 'chatgpt —Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ'\\)\n"
        f"‚Ä¢ –ù–∞–ø–∏—Å–∞—Ç—å '–º–æ–¥–µ–ª–∏' –∏–ª–∏ 'models' –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π"
    )
    
    await update.message.reply_markdown_v2(text=text)

async def models_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /models - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    try:
        init_client()
        logger.info("Fetching models list from OpenRouter")
        models_data = await fetch_models_data()

        if not models_data:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API.")
            return

        categories = categorize_models(models_data)

        category_titles = {
            "free": "–ë–ï–°–ü–õ–ê–¢–ù–´–ï –ú–û–î–ï–õ–ò:",
            "large_context": "–ú–û–î–ï–õ–ò –° –ë–û–õ–¨–®–ò–ú –ö–û–ù–¢–ï–ö–°–¢–û–ú (‚â•100K):",
            "specialized": "–°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ú–û–î–ï–õ–ò:",
            "paid": "–ü–õ–ê–¢–ù–´–ï –ú–û–î–ï–õ–ò:",
        }

        message = "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n\n"
        max_items_per_category = 20

        for key in ["free", "large_context", "specialized", "paid"]:
            models = categories.get(key, [])
            if not models:
                continue

            message += f"{category_titles[key]}\n"
            displayed_models = models[:max_items_per_category]
            for model in displayed_models:
                model_id = model.get('id', 'Unknown')
                context_length = model.get('context_length', 0)
                context_kb = context_length / 1024 if context_length else 0
                context_str = f"{context_kb:.0f}K" if context_kb > 0 else 'N/A'
                message += f"‚Ä¢ {model_id} ({context_str})\n"

            remaining = len(models) - len(displayed_models)
            if remaining > 0:
                message += f"‚Ä¶–∏ –µ—â–µ {remaining} –º–æ–¥–µ–ª–µ–π –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n"

            message += "\n"

        # –†–∞–∑–±–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        max_length = 3000
        message_parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]

        for part in message_parts:
            await update.message.reply_text(part)

        logger.info("Models list sent successfully")
    except Exception as e:
        logger.error(f"Error fetching models list: {str(e)}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
