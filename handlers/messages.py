import logging
from telegram import Update
from telegram.ext import ContextTypes
from utils.helpers import escape_markdown_v2
from services.generation import generate_text, generate_image
from services.memory import add_message, get_history, get_user_summary
from config import BOT_CONFIG

logger = logging.getLogger(__name__)

async def get_capabilities() -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."""
    try:
        response = await client.models.list()
        capabilities = ["todo: –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å, —á—Ç–æ–± –æ—Ç–≤–µ—á–∞–ª —Å —É—á—ë—Ç–æ–º –ø—Ä–æ–º—Ç–∞ –∏ readme git) \n\n –í–æ—Ç —á—Ç–æ —è —É–º–µ—é:\n\nü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n"]
        current_part = capabilities[0]
        
        for model in response.data:
            model_data = model if isinstance(model, dict) else model.model_dump()
            model_id = model_data.get('id', 'Unknown')
            context_length = model_data.get('context_length', 'N/A')
            pricing = model_data.get('pricing', {})
            prompt_price = pricing.get('prompt', 'N/A') if isinstance(pricing, dict) else 'N/A'
            
            model_info = f"‚Ä¢ {model_id} (–º–∞–∫—Å. –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context_length})\n"
            if prompt_price != 'N/A':
                model_info += f"  ‚îî‚îÄ –¶–µ–Ω–∞: ${prompt_price}/1K —Ç–æ–∫–µ–Ω–æ–≤\n"
            
            if len(current_part + model_info) > 3000:
                capabilities.append(model_info)
                current_part = model_info
            else:
                current_part += model_info
        
        instructions = "\nüí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n"
        instructions += f"‚Ä¢ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å - –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ {BOT_CONFIG['DEFAULT_MODEL']}\n"
        instructions += "‚Ä¢ –£–∫–∞–∂–∏ –º–æ–¥–µ–ª—å –≤ –Ω–∞—á–∞–ª–µ ('chatgpt —Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ')\n"
        instructions += "‚Ä¢ –ò–ª–∏ –≤ –∫–æ–Ω—Ü–µ ('—Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ —á–µ—Ä–µ–∑ claude')\n"
        instructions += "‚Ä¢ –î–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–π '–Ω–∞—Ä–∏—Å—É–π' –∏–ª–∏ '—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É'\n"
        instructions += "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π /new –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é)\n"
        instructions += "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π /clear –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏"
        
        if len(current_part + instructions) > 3000:
            capabilities.append(instructions)
        else:
            capabilities[-1] += instructions
        
        return capabilities
    except Exception as e:
        logger.error(f"Error getting capabilities: {str(e)}")
        return ["–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö."]

async def route_request(text: str, bot_username: str | None) -> tuple[str, str, str | None]:
    """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É —Å–µ—Ä–≤–∏—Å—É."""
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    if text.lower() in ["—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏", "capabilities", "help", "–ø–æ–º–æ—â—å"]:
        return "capabilities", await get_capabilities(), None
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if text.lower().startswith(("–Ω–∞—Ä–∏—Å—É–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "—Å–æ–∑–¥–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")):
        return "image", text, None
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    model = None
    prompt = text
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–∞—á–∞–ª–µ
    model_keywords = {
        "chatgpt": "openai/gpt-3.5-turbo",
        "claude": "anthropic/claude-3-opus-20240229",
        "deepseek": "deepseek/deepseek-chat-33b"
    }
    
    found_model_keyword = False
    for keyword, model_name in model_keywords.items():
        if prompt.lower().startswith(keyword):
            model = model_name
            prompt = prompt[len(keyword):].strip()
            found_model_keyword = True
            break
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ü–µ
    if not found_model_keyword:
        for keyword, model_name in model_keywords.items():
            if prompt.lower().endswith(f"—á–µ—Ä–µ–∑ {keyword}"):
                model = model_name
                prompt = prompt[:-len(f"—á–µ—Ä–µ–∑ {keyword}")].strip()
                found_model_keyword = True
                break
    
    if found_model_keyword:
        logger.info(f"Routing to text generation with specified model: {model}. Clean prompt: '{prompt}'")
    else:
        model = BOT_CONFIG["DEFAULT_MODEL"]
        logger.info(f"Routing to text generation with default model: {model}. Clean prompt: '{prompt}'")

    return "text", prompt, model

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    message = update.message
    if not message or not message.text:
        return

    bot_username = context.bot.username
    text = message.text
    chat_type = message.chat.type
    effective_text = text
    chat_id = str(message.chat.id)
    user_id = str(message.from_user.id)

    is_mentioned = False
    if chat_type in ['group', 'supergroup']:
        mention = f"@{bot_username}"
        if effective_text.startswith(mention):
            effective_text = effective_text[len(mention):].strip()
            is_mentioned = True
        elif mention in effective_text:
            logger.debug(f"Ignoring message in group {message.chat.id} - mention not at start.")
            return
        else:
            logger.debug(f"Ignoring message in group {message.chat.id} as bot was not mentioned.")
            return

        if not effective_text:
            logger.debug(f"Ignoring message in group {message.chat.id} as it only contained mention.")
            return

    logger.info(f"Processing message from {message.from_user.name} in chat {message.chat.id}: '{effective_text}'")

    service_type, clean_prompt, model_name = await route_request(effective_text, bot_username if is_mentioned else None)

    if not clean_prompt and service_type != "capabilities":
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–ª–∏ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞.")
        return

    try:
        if service_type == "capabilities":
            for message_part in clean_prompt:
                await update.message.reply_text(message_part)
        elif service_type == "image":
            await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...")
            image_url = await generate_image(clean_prompt)
            if image_url.startswith("http"):
                logger.info(f"Bot image response (PiAPI): {image_url}")
                escaped_prompt = escape_markdown_v2(clean_prompt)
                caption = f"üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {escaped_prompt}\n\\(–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é PiAPI\\.ai\\)"
                await update.message.reply_photo(image_url, caption=caption, parse_mode='MarkdownV2')
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏
                add_message(chat_id, user_id, "user", "image", clean_prompt)
                add_message(chat_id, user_id, "assistant", "image", f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
            else:
                logger.info(f"Bot image error response (PiAPI): {image_url}")
                await update.message.reply_text(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_url}")
        elif service_type == "text" and model_name:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏–∏
            add_message(chat_id, user_id, "user", model_name, clean_prompt)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            response_text = await generate_text(clean_prompt, model_name, chat_id, user_id)
            logger.info(f"Bot response ({model_name}): {response_text}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏
            add_message(chat_id, user_id, "assistant", model_name, response_text)
            
            escaped_model_name = escape_markdown_v2(model_name)
            escaped_response_text = escape_markdown_v2(response_text)
            await update.message.reply_markdown_v2(f"–û—Ç–≤–µ—Ç –æ—Ç `{escaped_model_name}`:\n\n{escaped_response_text}")
    except Exception as e:
        logger.error(f"Error handling message: {e}", exc_info=True)
        error_message_escaped = escape_markdown_v2(str(e))
        await update.message.reply_markdown_v2(f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\\.\n`{error_message_escaped}`") 