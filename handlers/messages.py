import logging
from telegram import Update
from telegram.ext import ContextTypes
from handlers.commands import MODELS_HINT_TEXT
from services.generation import (
    CATEGORY_TITLES,
    build_models_messages,
    generate_image,
    generate_text,
)
from services.memory import add_message
from config import BOT_CONFIG

logger = logging.getLogger(__name__)

async def get_capabilities() -> list[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."""
    try:
        capabilities = await build_models_messages(
            ["free", "large_context", "specialized", "paid"],
            header="ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n\n",
            max_items_per_category=20,
        )

        if not capabilities:
            return ["–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö."]

        instructions = "üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n"
        instructions += f"‚Ä¢ –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å - –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ {BOT_CONFIG['DEFAULT_MODEL']}\n"
        instructions += "‚Ä¢ –£–∫–∞–∂–∏ –º–æ–¥–µ–ª—å –≤ –Ω–∞—á–∞–ª–µ ('chatgpt —Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ')\n"
        instructions += "‚Ä¢ –ò–ª–∏ –≤ –∫–æ–Ω—Ü–µ ('—Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø–æ–≥–æ–¥–µ —á–µ—Ä–µ–∑ claude')\n"
        instructions += "‚Ä¢ –î–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–π '–Ω–∞—Ä–∏—Å—É–π' –∏–ª–∏ '—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É'"

        if len(capabilities[-1] + instructions) > 3000:
            capabilities.append(instructions)
        else:
            capabilities[-1] += instructions

        return capabilities
    except Exception as e:
        logger.error(f"Error getting capabilities: {str(e)}")
        return ["–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö."]

async def send_models_by_request(
    message,
    order: list[str],
    header: str,
    max_items: int | None = 20,
) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏."""

    parts = await build_models_messages(order, header=header, max_items_per_category=max_items)
    if not parts:
        await message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    for part in parts:
        await message.reply_text(part)

async def route_request(text: str, bot_username: str | None) -> tuple[str, str, str | None]:
    """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É —Å–µ—Ä–≤–∏—Å—É."""
    text_lower = text.lower().strip()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    if text_lower in ["—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏", "capabilities", "help", "–ø–æ–º–æ—â—å"]:
        return "help", "help", None

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
    if text_lower in ["–º–æ–¥–µ–ª–∏", "models"]:
        return "models_hint", "", None

    model_aliases = {
        "–ø–æ–∫–∞–∂–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏": "free",
        "–ø–æ–∫–∞–∂–∏ –ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏": "paid",
        "–ø–æ–∫–∞–∂–∏ –º–æ–¥–µ–ª–∏ —Å –±–æ–ª—å—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º": "large_context",
        "–ø–æ–∫–∞–∂–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏": "specialized",
        "–ø–æ–∫–∞–∂–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏": "all",
    }

    if text_lower in model_aliases:
        return "models_category", model_aliases[text_lower], None

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if text_lower.startswith(("–Ω–∞—Ä–∏—Å—É–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–∞—Ä—Ç–∏–Ω–∫—É", "—Å–æ–∑–¥–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")):
        return "image", text, None
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    model = None
    prompt = text
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–∞—á–∞–ª–µ
    model_keywords = {
        "chatgpt": "openai/gpt-3.5-turbo",
        "claude": "anthropic/claude-3-haiku",
        "claude_opus": "anthropic/claude-3-opus",
        "claude_sonnet": "anthropic/claude-3-sonnet",
        "deepseek": "deepseek/deepseek-r1-distill-qwen-14b",
        "mistral": "mistralai/mistral-large-2407",
        "llama": "meta-llama/llama-3.1-8b-instruct:free",
        "meta": "meta-llama/llama-3.1-8b-instruct:free",
        "qwen": "qwen/qwen2.5-vl-3b-instruct:free",
        "fimbulvetr": "sao10k/fimbulvetr-11b-v2",
        "sao10k": "sao10k/fimbulvetr-11b-v2"
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–∞—á–∞–ª–µ –∑–∞–ø—Ä–æ—Å–∞
    words = prompt.lower().split()
    if words and words[0] in model_keywords:
        model = model_keywords[words[0]]
        prompt = " ".join(words[1:]).strip()
        return "text", prompt, model
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ü–µ –∑–∞–ø—Ä–æ—Å–∞
    for keyword, model_name in model_keywords.items():
        if prompt.lower().endswith(f"—á–µ—Ä–µ–∑ {keyword}"):
            model = model_name
            prompt = prompt[:-len(f"—á–µ—Ä–µ–∑ {keyword}")].strip()
            return "text", prompt, model
    
    return "text", prompt, None

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    message = update.message
    if not message or not message.text:
        return

    bot_username = context.bot.username
    text = message.text
    chat_type = message.chat.type
    effective_text = text
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logger.info(f"Received message: '{text}' from user {message.from_user.username} in chat {message.chat_id}")
    logger.info(f"Chat type: {chat_type}, Bot username: {bot_username}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –±–æ—Ç–∞ –≤ –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–∞—Ö
    if chat_type in ["group", "supergroup"]:
        if bot_username and f"@{bot_username}" in text:
            effective_text = text.replace(f"@{bot_username}", "").strip()
            logger.info(f"Group chat message, extracted text: '{effective_text}'")
        else:
            logger.info("Group chat message without bot mention, ignoring")
            return
    
    # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    logger.info(f"Routing request: '{effective_text}'")
    request_type, content, model = await route_request(effective_text, bot_username)
    logger.info(f"Request routed to: {request_type}, model: {model}")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
    if request_type == "help":
        logger.info("Processing help request")
        capabilities = await get_capabilities()
        for part in capabilities:
            await message.reply_text(part)
    elif request_type == "models_hint":
        logger.info("Providing models hint")
        await message.reply_text(MODELS_HINT_TEXT)
    elif request_type == "models_category":
        logger.info(f"Providing models list for category: {content}")
        if content == "all":
            await send_models_by_request(
                message,
                ["free", "large_context", "specialized", "paid"],
                MODELS_HINT_TEXT,
                max_items=None,
            )
        else:
            await send_models_by_request(
                message,
                [content],
                CATEGORY_TITLES.get(content, "–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π:"),
                max_items=20,
            )
    elif request_type == "image":
        logger.info(f"Processing image generation request: '{content}'")
        await message.reply_text("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        image_url = await generate_image(content)
        if image_url:
            await message.reply_photo(image_url)
        else:
            await message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    elif request_type == "text":
        logger.info(f"Processing text generation request: '{content}', model: {model}")
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        chat_id = str(message.chat_id)
        user_id = str(message.from_user.id)
        model_name = model or BOT_CONFIG["DEFAULT_MODEL"]
        add_message(chat_id, user_id, "user", model_name, content)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = await generate_text(content, model_name, chat_id, user_id)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        add_message(chat_id, user_id, "assistant", model_name, response)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        await message.reply_text(f"–û—Ç–≤–µ—Ç –æ—Ç {model_name}:\n\n{response}")
    else:
        logger.warning(f"Unknown request type: {request_type}")
        await message.reply_text("–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å.")
