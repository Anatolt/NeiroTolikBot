import logging
import os
from telegram import Update, BotCommand
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import re # Import re for escaping markdown
from openai import AsyncOpenAI
import json
from typing import Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Bot Configuration
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
DEFAULT_MODEL = "anthropic/claude-3-haiku"
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
BOT_REFERER = "https://t.me/NeiroTolikBot"
BOT_TITLE = "NeiroTolikBot"

# Initialize OpenAI client with async support
client = AsyncOpenAI(
    base_url=OPENROUTER_BASE_URL,
    api_key=OPENROUTER_API_KEY,
    default_headers={
        "HTTP-Referer": BOT_REFERER,
        "X-Title": BOT_TITLE
    }
)

# Enable logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- Placeholder Functions ---
async def generate_text(prompt: str, model: str) -> str:
    """Generate text using OpenRouter API."""
    try:
        response = await client.chat.completions.create(  # Ð¢ÐµÐ¿ÐµÑ€ÑŒ await Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Error generating text: {str(e)}")
        return f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°: {str(e)}"

async def generate_image(prompt: str) -> str:
    """Generate image using OpenRouter's Qwen model."""
    try:
        response = await client.images.generate(
            model="qwen/qwen2.5-vl-3b-instruct:free",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )
        return response.data[0].url
    except Exception as e:
        logger.error(f"Error generating image: {str(e)}")
        return f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {str(e)}"

# Ð”Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ð½Ð¾Ð²ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÐµÐ¹
async def get_capabilities() -> str:
    """Get and format information about available models."""
    try:
        response = await client.models.list()
        
        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¹ Ð²Ð¸Ð´
        capabilities = ["Ð’Ð¾Ñ‚ Ñ‡Ñ‚Ð¾ Ñ ÑƒÐ¼ÐµÑŽ:\n\nðŸ¤– Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:\n"]
        current_part = capabilities[0]
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ°Ðº ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
        for model in response.data:
            model_data = model if isinstance(model, dict) else model.model_dump()  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ model_dump Ð²Ð¼ÐµÑÑ‚Ð¾ dict
            model_id = model_data.get('id', 'Unknown')
            context_length = model_data.get('context_length', 'N/A')
            pricing = model_data.get('pricing', {})
            prompt_price = pricing.get('prompt', 'N/A') if isinstance(pricing, dict) else 'N/A'
            
            model_info = f"â€¢ {model_id} (Ð¼Ð°ÐºÑ. ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {context_length})\n"
            if prompt_price != 'N/A':
                model_info += f"  â””â”€ Ð¦ÐµÐ½Ð°: ${prompt_price}/1K Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²\n"
            
            # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐºÑƒÑ‰Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ ÑÑ‚Ð°Ð½ÐµÑ‚ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ð¾Ð¹, Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ
            if len(current_part + model_info) > 3000:  # ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ð°Ñ Ð¾Ñ‚ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð² 4096
                capabilities.append(model_info)
                current_part = model_info
            else:
                current_part += model_info
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
        instructions = "\nðŸ’¡ ÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ:\n"
        instructions += "â€¢ ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ ÑÐ²Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ - Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ñ‡ÐµÑ€ÐµÐ· claude-3-haiku\n"
        instructions += "â€¢ Ð£ÐºÐ°Ð¶Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ ('chatgpt Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¾ Ð¿Ð¾Ð³Ð¾Ð´Ðµ')\n"
        instructions += "â€¢ Ð˜Ð»Ð¸ Ð² ÐºÐ¾Ð½Ñ†Ðµ ('Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¾ Ð¿Ð¾Ð³Ð¾Ð´Ðµ Ñ‡ÐµÑ€ÐµÐ· claude')\n"
        instructions += "â€¢ Ð”Ð»Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð¾Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ 'Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹' Ð¸Ð»Ð¸ 'ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ'"
        
        if len(current_part + instructions) > 3000:
            capabilities.append(instructions)
        else:
            capabilities[-1] += instructions
        
        return capabilities  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
    except Exception as e:
        logger.error(f"Error getting capabilities: {str(e)}")
        return ["Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð¸Ñ… Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑÑ…."]

# --- Routing Logic ---
async def route_request(text: str, bot_username: str | None) -> tuple[str, str, str | None]:
    """
    Parses the message text, identifies the target service (text/image)
    and model (if specified), and extracts the clean prompt.

    Returns:
        tuple: (service_type, clean_prompt, model_name)
               service_type: "text" or "image"
               clean_prompt: The user's prompt without keywords/mentions
               model_name: The requested model or None if default or image
    """
    text_lower = text.lower()
    prompt = text
    model = None
    service = "text" # Default to text generation

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÐµÐ¹
    capability_keywords = ["Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ ÑƒÐ¼ÐµÐµÑˆÑŒ", "Ñ‚Ð²Ð¾Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸", "Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ", "ÑÐ¿Ñ€Ð°Ð²ÐºÐ°", "help"]
    if any(keyword in text_lower for keyword in capability_keywords):
        capabilities = await get_capabilities()
        # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ ÑÐµÑ€Ð²Ð¸ÑÐ° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÑÐ¿Ñ€Ð°Ð²ÐºÐ¸
        return "capabilities", capabilities, None

    # In groups, mention is already removed before calling this function if check passed
    # If called from private chat, bot_username is None

    # --- Keyword-based Routing ---
    image_keywords = ["Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹", "ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ°", "Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", "ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ", "generate image"]
    # Use word boundaries to avoid matching parts of words, check start/end
    if any(f" {keyword} " in f" {text_lower} " or text_lower.startswith(keyword) or text_lower.endswith(keyword) for keyword in image_keywords):
        service = "image"
        # More robust keyword removal
        for keyword in image_keywords:
            # Try removing "keyword " or " keyword" or just "keyword" if it's the whole prompt
            if prompt.lower().startswith(keyword + " "):
                prompt = prompt[len(keyword) + 1:].strip()
            elif prompt.lower().endswith(" " + keyword):
                prompt = prompt[:-len(keyword) - 1].strip()
            elif prompt.lower() == keyword:
                 prompt = ""
                 break
            # Simple replacement as fallback (might catch parts of words in some cases)
            prompt = prompt.replace(keyword, "", 1).strip()
            prompt = prompt.replace(keyword.capitalize(), "", 1).strip() # Handle capitalization

        logger.info(f"Routing to image generation. Clean prompt: '{prompt}'")
        return service, prompt, None # Model not relevant for image placeholder

    # --- Model Specification Routing (Example) ---
    model_keywords = {
        "deepseek": "deepseek/deepseek-r1-distill-qwen-14b",
        "chatgpt": "mistralai/mistral-large-2407",  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Mistral ÐºÐ°Ðº Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñƒ ChatGPT
        "claude": "anthropic/claude-2.1:beta",
        "qwen": "qwen/qwen2.5-vl-3b-instruct:free",
        "llama": "meta-llama/llama-3.1-8b-instruct:free",
        "fimbulvetr": "sao10k/fimbulvetr-11b-v2"
    }

    found_model_keyword = None
    # Check for formats like "... via model", "... using model", "model ..."
    for keyword, model_id in model_keywords.items():
        # Check at the end of the string (e.g., "prompt text via chatgpt")
        if text_lower.endswith(f" via {keyword}") or text_lower.endswith(f" Ñ‡ÐµÑ€ÐµÐ· {keyword}"):
            model = model_id
            phrase_len = len(f" via {keyword}") if text_lower.endswith(f" via {keyword}") else len(f" Ñ‡ÐµÑ€ÐµÐ· {keyword}")
            prompt = prompt[:-phrase_len].strip()
            found_model_keyword = keyword
            break
        # Check at the beginning (e.g., "chatgpt prompt text")
        elif text_lower.startswith(keyword + " "):
             model = model_id
             prompt = prompt[len(keyword):].strip()
             found_model_keyword = keyword
             break
        # Check for simple keyword presence as a fallback (less precise)
        # elif f" {keyword} " in f" {text_lower} ": # Avoid using this as it conflicts easily
        #     model = model_id
        #     # Removing the keyword here is tricky, might leave prompt fragmented
        #     # Consider just using the model if found this way, without altering prompt much
        #     logger.warning(f"Found model keyword '{keyword}' mid-prompt. Extraction might be imperfect.")
        #     prompt = prompt.replace(keyword, "").strip() # Simplistic removal
        #     found_model_keyword = keyword
        #     break


    if found_model_keyword:
         logger.info(f"Routing to text generation with specified model: {model}. Clean prompt: '{prompt}'")
    else:
        model = DEFAULT_MODEL
        logger.info(f"Routing to text generation with default model: {model}. Clean prompt: '{prompt}'")


    return service, prompt, model


# --- Message Handler ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handles incoming messages, routes them, and calls the appropriate generator."""
    message = update.message
    if not message or not message.text:
        return

    bot_username = context.bot.username
    text = message.text
    chat_type = message.chat.type
    effective_text = text # Keep original text for routing if needed, modify this one

    # In groups, only respond if mentioned
    is_mentioned = False
    if chat_type in ['group', 'supergroup']:
        mention = f"@{bot_username}"
        if effective_text.startswith(mention):
             effective_text = effective_text[len(mention):].strip()
             is_mentioned = True
        elif mention in effective_text: # Mention somewhere else? Less common for direct commands.
             # We could ignore these, or try to handle, but for now, require start mention.
             logger.debug(f"Ignoring message in group {message.chat.id} - mention not at start.")
             return
        else:
            logger.debug(f"Ignoring message in group {message.chat.id} as bot was not mentioned.")
            return

        if not effective_text: # Ignore message if it only contained the mention
             logger.debug(f"Ignoring message in group {message.chat.id} as it only contained mention.")
             return

    # If it's a private chat or the bot was mentioned in a group
    logger.info(f"Processing message from {message.from_user.name} in chat {message.chat.id}: '{effective_text}'")

    # Route the request using the text *after* removing the mention (if any)
    service_type, clean_prompt, model_name = await route_request(effective_text, bot_username if is_mentioned else None)

    if not clean_prompt and service_type != "capabilities":  # Ð˜Ð·Ð¼ÐµÐ½Ð¸Ð¼ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ
        await update.message.reply_text("ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÑƒÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ÑÐ»Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ð¸Ð»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°.")
        return

    # Call the appropriate function based on routing
    try:
        if service_type == "capabilities":
            # clean_prompt Ñ‚ÐµÐ¿ÐµÑ€ÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
            for message_part in clean_prompt:
                await update.message.reply_text(message_part)
        elif service_type == "image":
            response_text = await generate_image(clean_prompt)
            await update.message.reply_text(response_text)
        elif service_type == "text" and model_name:
            response_text = await generate_text(clean_prompt, model_name)
            await update.message.reply_text(response_text)
    except Exception as e:
        logger.error(f"Error handling message: {e}", exc_info=True)
        await update.message.reply_text("Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°.")


async def post_init(application: Application) -> None:
    """Sets bot commands after initialization."""
    await application.bot.set_my_commands([
        BotCommand("start", "ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³"),
        # Add more commands if needed
    ])
    logger.info("Bot commands set.")

def escape_markdown_v2(text: str) -> str:
    """Escapes characters for Telegram MarkdownV2."""
    # Chars to escape: _ * [ ] ( ) ~ ` > # + - = | { } . !
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Sends a welcome message when the /start command is issued."""
    user = update.effective_user
    user_mention = user.mention_markdown_v2() # Use Markdown mention
    # Use MarkdownV2 for the reply
    default_model_escaped = escape_markdown_v2(DEFAULT_MODEL) # Escape model name

    # Using MarkdownV2 with \n for line breaks
    text = (
        f"ÐŸÑ€Ð¸Ð²ÐµÑ‚, {user_mention}\\! Ð¯ Ð±Ð¾Ñ‚\\-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº\\.\n\n"
        f"ðŸ“ Ð¡Ð¿Ñ€Ð¾ÑÐ¸ Ð¼ÐµÐ½Ñ Ñ‡Ñ‚Ð¾\\-Ð½Ð¸Ð±ÑƒÐ´ÑŒ, Ð¸ Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ñƒ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ `{default_model_escaped}`\\.\n"
        f"ðŸŽ¨ ÐŸÐ¾Ð¿Ñ€Ð¾ÑÐ¸ Ð½Ð°Ñ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ \\(Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'Ð½Ð°Ñ€Ð¸ÑÑƒÐ¹ Ð·Ð°ÐºÐ°Ñ‚ Ð½Ð°Ð´ Ð¼Ð¾Ñ€ÐµÐ¼'\\)\\.\n"
        f"ðŸ¤– Ð¥Ð¾Ñ‡ÐµÑˆÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸? Ð£ÐºÐ°Ð¶Ð¸ ÐµÐµ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° \\(Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, '\\.\\.\\. Ñ‡ÐµÑ€ÐµÐ· deepseek', '\\.\\.\\. via claude'\\) Ð¸Ð»Ð¸ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ \\(Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'chatgpt ÐºÐ°ÐºÐ¾Ð¹ ÑÐµÐ³Ð¾Ð´Ð½Ñ Ð´ÐµÐ½ÑŒ?'\\)\\.\n"
        f"   Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚ÑÑ: deepseek, chatgpt, claude\\."
    )

    await update.message.reply_markdown_v2(
        text=text,
        # disable_web_page_preview=True # Still useful
    )


# --- Main Function ---
def main() -> None:
    """Start the bot."""
    # Check if environment variables are set
    if not TELEGRAM_BOT_TOKEN or not OPENROUTER_API_KEY:
        logger.error("Please set TELEGRAM_BOT_TOKEN and OPENROUTER_API_KEY in .env file")
        return

    # Create the Application and pass it your bot's token.
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).post_init(post_init).build()

    # --- Handlers ---
    # Handle /start command
    application.add_handler(CommandHandler("start", start))

    # Handle regular messages using the routing logic
    # Ensure it handles both private chats and mentions in groups
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Run the bot until the user presses Ctrl-C
    logger.info("Starting bot polling...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main() 
